---
title: "Prédire la consommation électrique en France"
subtitle: Projet ML pour la prévision, encadré par Yannig Goude
output: html_document
author: Guillaume Principato et Valérie Castin
date: "15/03/22"
---

<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*Je vais remettre en forme pour que les figures soient plus jolies, pour l'instant c'est un premier jet*

*Introduction à écrire*


## 1 Importation et prétraitement des données

```{r packages, echo=FALSE, include=FALSE}
rm(list=objects())

library(tidyverse)
library(readr)
library(dplyr)
library(lubridate)
library(xts)
library(mgcv)
library(mgcViz)
library(gridExtra)
library(yarrr)
library(qgam)
library(magrittr)
library(rpart)
library(party)
library(tree)
library(rpart.plot)
library(progress)
library(plotmo)
library(caret)
library(randomForest)
library(ranger)
library(opera)
library(corrplot)
library(vip)
library(dygraphs)

set.seed(1)

load("DONNEES/data.rda")
load("MODELES/forets_ouvre.rda")
load("MODELES/forets_we.rda")
load("MODELES/GAM.rda")
load("MODELES/stacking.rda")
```

Les données que nous avons utilisées sont des données EDF, qui nous ont été fournies directement par Yannig Goude. Nous avons donc pu nous concentrer sur les modèles sans avoir à nettoyer la base de données. Elles concernent la consommation électrique globale française (particuliers, entreprises et bâtiments publics confondus), échantillonnée par demi-heure de janvier 2012 à octobre 2022. Il y a en tout 24 variables, ce qui fait un total de $4.5\times 10^{6}$ observations.

### 1.1 Les principales variables du problème

Les variables que nous avons exploitées sont les suivantes.

  - Variables temporelles
    + **tod** : time of day, valeur numérique entre 0 et 1 indiquant le moment de la journée
    + **toy** : time of year, valeur numérique entre 0 et 1 indiquant le moment de l'année
    + **Month** : chaîne de caractères indiquant le mois
    + **WeekDays** : chaîne de caractères indiquant le jour de la semaine
    + **BH** : 1 si l'on est un jour férié, 0 sinon
    + **DLS** : 1 si l'on est en heure d'hiver, 0 sinon
    + **Summer_break** : variable à deux niveaux (0 et 10) pour indiquer les vacances d'été
    + **Christmas_break** : variable à deux niveaux (0 et 20) pour indiquer les vacances de Noël
    
  - Variables de consommation électrique (valeurs numériques)
    + **Load** : consommation dans toute la France échantillonnée au pas demi-heure
    + **Load.48** : consommation 24 heures (soit 48 demi-heures) avant
  - Prévisions RTE (valeurs numériques)
    + **Forecast_RTE_dayahead** : prévision de la consommation réalisée la veille (entre 18h et 20h) par RTE pour le lendemain
    + **Forecast_RTE_intraday** : prévision de la consommation réalisée une heure avant par RTE
  - Variables liées à la température (valeurs numériques)
    + **Temp** : température moyenne mesurée par un ensemble de stations météo en France métropolitaine
    + **Temp_s95** : lissage exponentiel de Temp, avec un facteur de lissage $\alpha = 0.95$
    + **Temp_s99** : lissage exponentiel de Temp, avec un facteur de lissage $\alpha = 0.99$
    + **Temp_s95_min** : minimum des températures mesurées par les différentes stations météo, après lissage avec $\alpha = 0.95$
    + **Temp_s99_min** : minimum des températures mesurées par les différentes stations météo, après lissage avec $\alpha = 0.99$
    + **Temp_s95_max** : maximum des températures mesurées par les différentes stations météo, après lissage avec $\alpha = 0.95$
    + **Temp_s99_max** : maximum des températures mesurées par les différentes stations météo, après lissage avec $\alpha = 0.99$.

### 1.2 Analyse descriptive préliminaire

Commençons par afficher la consommation électrique sur un mois, par exemple avril 2012.

```{r, echo=FALSE, include=TRUE}
knitr::include_graphics('FIGURES/avril_2012.png')
```


On observe plusieurs périodicités dans la série temporelle :

- des oscillations journalières, de période 24h, avec des pics de consommation à certaines heures
- une périodicité hebdomadaire, avec une nette différence entre les jours ouvrés et les week-ends (ceux-ci coïncidant avec une consommation plus faible).

On s'attend aussi à avoir une périodicité annuelle. Pour la voir, nous représentons la consommation entre 2012 et 2014 pour un jour de la semaine fixé (par exemple le mardi) à une heure donnée (ici 12h), sinon il y a trop de données pour que les courbes soient lisibles.

```{r, echo=FALSE, include=TRUE}
knitr::include_graphics('FIGURES/mardi_12h.png')
```

On voit que la consommation est nettement plus importante l'hiver, et on retrouve les vacances d'été et les vacances de Noël en creux.

Ces observations nous incitent à traiter différemment chaque heure de la journée, et à distinguer les jours ouvrés des jours fériés, ce que nous faisons dans la sous-partie suivante. Quelles sont ensuite les variables explicatives les plus pertinentes pour prédire la consommation ? Nous ferons une étude plus approfondie dans la partie sur les forêts aléatoires, en nous fondant sur l'importance des variables, mais nous pouvons dans un premier temps afficher la corrélation entre les variables.

```{r, echo = FALSE, include = TRUE}
knitr::include_graphics('FIGURES/corr.png')
```

La température (telle quelle ou lissée) apparaît comme étant très anticorrélée à la consommation, ce qui est naturel : lorsqu'il fait froid, les bâtiments sont chauffés, ce qui consomme beaucoup. L'effet de la climatisation lorsqu'il fait chaud compense un peu cette tendance, mais implique une augmentation moindre de la consommation. La consommation de la veille, **Load.48**, est au contraire très corrélée à **Load**. Quant à **tod** et **toy**, elles sont assez faiblement corrélées à **Load** car la tendance s'inverse au fil de leur augmentation : par exemple pour **toy**, la corrélation est d'abord négative, car plus on s'éloigne de janvier et plus les températures remontent, induisant une baisse de la consommation, mais dès que l'automne puis l'hiver reviennent, la corrélation devient positive, et les deux effets se compensent.

### 1.3 Découpage du jeu de données

En vue d'appliquer des modèles d'apprentissage, il nous faut séparer les données qui ont été obtenues dans des conditions trop différentes, pour que l'hypothèse de données identiquement distribuées soit raisonnablement satisfaite. Tout d'abord, les données de la période covid (notamment celles de l'année 2020) ne peuvent vraisemblablement pas être traitées comme celles des années précédentes. Nous choisissons donc comme ensemble d'entraînement la période de 2012 à 2018 inclus, et l'année 2019 sert d'ensemble de validation. Nous enlevons ensuite les jours fériés, qui correspondent à un changement ponctuel de la consommation, et nous séparons les jours ouvrés des week-ends, en vertu des observations réalisées dans la sous-partie précédente. Nous allons nous concentrer dans la suite sur le cas des jours ouvrés, la prédiction pour les week-ends étant très similaire et risquant d'alourdir le rapport inutilement.

Pour avoir des modèles aussi précis que possible, mais aussi alléger le coût d'entraînement, puisque notre jeu de données est assez volumineux, nous avons entraîné un modèle différent par demi-heure. Nous avons sélectionné 24 demi-heures sur 48 (les premières demi-heures de chaque heure), pour faciliter l'affichage des résultats : cela ne change rien aux méthodes étudiées. Nous obtenons ainsi les jeux de données :

- **d_ent_ouvre_i** pour $1\le i\le 24$, où l'on n'a gardé que les jours ouvrés dans **d_ent**, à l'heure $i$,
- **d_test_ouvre_i** pour $1\le i\le 24$, où l'on n'a gardé que les jours ouvrés dans **d_test**, à l'heure $i$.


## 2 Évaluation des modèles : quelques repères

Pour évaluer la performance de nos modèles, nous introduisons la classique perte quadratique (RMSE), et également l'erreur absolue moyenne en pourcentage (MAPE), que nous allons majoritairement exploiter en tant que grandeur "absolue" sans dimension :

$$\text{RMSE}(\varepsilon) = \sqrt{\frac{1}{T}\sum_{i=1}^T \varepsilon_i^2},$$
et
$$\text{MAPE}(Y,\hat{Y}) = 100 \times \frac{1}{T}\sum_{i=1}^T\left \lvert \frac{Y_i-\hat{Y}_i}{Y_i}\right \rvert.$$

Pour avoir une idée du positionnement de nos modèles en termes de performance, et de l'utilité de recourir au machine learning pour répondre à notre problème, nous pouvons nous comparer :

- au modèle naïf *à faire : je pensais à Load.48, est-ce que tu aurais d'autres idées ? _Je pense que c'est effectivement bien de prendre Load.48*
- aux prévisions RTE : sur le jeu de données test (année 2019), on calcule les MAPE suivants pour **Forecast_RTE_intraday** pour les jours ouvrés (en pourcentage, dans l'ordre croissant par heure)

```{r, echo=FALSE, include=TRUE}
mape_ouvre_RTE <- c()
for(i in c(1:H))
{
  mape_ouvre_RTE <- c(mape_ouvre_RTE, mape(eval(parse(text=paste("d_test_ouvre", i, sep="_")))$Load, eval(parse(text=paste("d_test_ouvre", i, sep="_")))$Forecast_RTE_intraday))
}
plot(mape_ouvre_RTE, main = "MAPE de RTE en fonction de l'heure (année 2019)", xlab = "Heure", ylab = "MAPE (%)", type="l", ylim= c(0,1.7), lab=c(5,4,0), col="blue")
```


Soulignons que dans ses prévisions une heure à l'avance, RTE ne dispose que de prévisions météo, alors que nos modèles exploitent des valeurs de température effective, ce qui joue à notre avantage.
*c'est des prévisions une heure à l'avance ? c'est pas des prévisions qui sont toutes faites en même temps à minuit pour le lendemain ?*

## 3 Forêts aléatoires

Un premier modèle assez adapté à notre problématique est celui des forêts aléatoires. Dans un premier temps, nous avons entraîné une forêt sur l'ensemble des données, sans la séparation des heures et des jours ouvrés/week-ends. Nous obtenons un MAPE de 1.8% sur les données test. Nous avons ensuite séparé les données conformément à la partie 1.3, et les résultats sont nettement meilleurs : c'est donc ce choix que nous développons dans cette partie. Nous avons utilisé le package *ranger*, et mis dans chaque modèle toutes les variables explicatives potentiellement pertinentes.

### 3.1 Choix des paramètres sur un jeu de données

Les paramètres à choisir pour définir nos forêts aléatoires sont les suivants.

- **mtry** : nombre de variables sélectionnées à chaque nouvelle coupure dans les arbres. Nous réalisons une validation croisée sur le modèle **d_ent_ouvre_1**, les autres modèles se comportant de façon similaire, et choisissons **mtry** = 8, car la courbe est à peu près constante à partir de cette valeur.


```{r, out.width='80%', fig.align='center', fig.show='hold', echo = F}
knitr::include_graphics('FIGURES/choix_mtry_forets.png')
```


- **min.node.size** : les fluctuations de RMSE induites par le changement de ce paramètre sont faibles, d'après la courbe ci-dessous. Nous laissons donc **min.node.size** à sa valeur par défaut (5).

```{r, out.width='80%', fig.align='center', fig.show='hold', echo = F}
knitr::include_graphics('FIGURES/choix_minnode_forets.png')
```


- **num.trees** : au vu de la courbe ci-dessous, nous choisissons de prendre 150 arbres, ce qui est un peu au-delà de la valeur où la courbe forme un coude, mais nous pouvons nous le permettre car nos jeux de données par heure ne sont pas très volumineux.

```{r, out.width='80%', fig.align='center', fig.show='hold', echo = F}
knitr::include_graphics('FIGURES/choix_ntree_forets.png')
```


### 3.2 Entraînement et évaluation des modèles

Une fois les paramètres choisis, nous pouvons entraîner nos modèles avec les variables explicatives suivantes.

```{r, eval=FALSE, echo=TRUE}
"Load ~ Temp_s99+toy+WeekDays+Temp_s95+Load.48+Christmas_break+Summer_break+DLS+Temp+Temp_s95_min+Temp_s95_max+Temp_s99_min+Temp_s99_max"
```

```{r, echo=FALSE}
# calcul des prédictions
for(i in c(1:H))
{
  assign(paste("pred_foret_ouvre", i, sep="_"), predict(eval(parse(text=paste("foret_ouvre", i, sep="_"))), data = eval(parse(text=paste("d_test_ouvre", i, sep="_")))))
}
```

```{r, echo=FALSE, include=TRUE}
# affichage des MAPE
mape_ouvre <- c()
for(i in c(1:H))
{
  mape_ouvre <- c(mape_ouvre, mape(eval(parse(text=paste("d_test_ouvre", i, sep="_")))$Load, eval(parse(text=paste("pred_foret_ouvre", i, sep="_")))$predictions))
}

plot(mape_ouvre, main = "MAPE en fonction de l'heure, jours ouvrés (année 2019)", xlab = "Heure", ylab = "MAPE (%)", type="l", ylim= c(0,1.7), lab=c(5,4,0), col="blue")
lines(mape_ouvre_RTE, col="red")
legend(x="bottomright", legend=c("foret","RTE"), col=c("blue","red"), pch=c(15,15))
```

Nous affichons l'attache aux données et la prédiction pour le modèle **foret_ouvre_12**. *Est-ce qu'on n'overfitte pas un peu ?*

```{r, echo=FALSE, include=TRUE}
# midi
#imp_12 <- importance(foret_ouvre_12)
#imp_12[order(imp_12, decreasing=TRUE)]

#rmse(d_test_ouvre_12$Load-pred_foret_ouvre_12$predictions)
#mape(d_test_ouvre_12$Load,pred_foret_ouvre_12$predictions)

# affichage sur les données d'entraînement
# d_plot_ouvre_12 <- filter(d_ent_ouvre_12, Year=="2018")
# f_plot_ouvre_12 <- predict(foret_ouvre_12, data = d_plot_ouvre_12)
# plot(d_plot_ouvre_12$toy, d_plot_ouvre_12$Load, main = "Entraînement jours ouvrés à midi", xlab = "Date (année 2018)", ylab = "Consommation (MWh)", type="l", lab=c(5,4,0))
# lines(d_plot_ouvre_12$toy, f_plot_ouvre_12$predictions, col='red')
# 
# # affichage sur les données test
# plot(d_test_ouvre_12$toy, d_test_ouvre_12$Load, main = "Validation jours ouvrés à midi", xlab = "Date (année 2019)", ylab = "Consommation (MWh)", type="l", lab=c(5,4,0))
# lines(d_test_ouvre_12$toy, pred_foret_ouvre_12$predictions, col='red')


# de minuit à une heure
#imp_1 <- importance(foret_ouvre_1)
#imp_1[order(imp_1, decreasing=TRUE)]

#rmse(d_test_ouvre_1$Load-pred_foret_ouvre_1$predictions)
#mape(d_test_ouvre_1$Load,pred_foret_ouvre_1$predictions)

# affichage sur les données d'entraînement
d_plot_ouvre_1 <- filter(d_ent_ouvre_1, Year=="2018")
f_plot_ouvre_1 <- predict(foret_ouvre_1, data = d_plot_ouvre_1)
plot(d_plot_ouvre_1$toy, d_plot_ouvre_1$Load, main = "Entraînement jours ouvrés à midi", xlab = "Date (année 2018)", ylab = "Consommation (MWh)", type="l", lab=c(5,4,0))
lines(d_plot_ouvre_1$toy, f_plot_ouvre_1$predictions, col='red')
legend(x="bottomleft", legend=c("données","foret_ouvre_12"), col=c("black","red"), pch=c(15,15))

# affichage sur les données test
plot(d_test_ouvre_1$toy, d_test_ouvre_1$Load, main = "Validation jours ouvrés à midi", xlab = "Date (année 2019)", ylab = "Consommation (MWh)", type="l", lab=c(5,4,0))
lines(d_test_ouvre_1$toy, pred_foret_ouvre_1$predictions, col='red')
legend(x="bottomleft", legend=c("données","foret_ouvre_12"), col=c("black","red"), pch=c(15,15))
```

*analyse des résidus à faire ?*

### 3.3 Importance des variables

Enfin, les forêts aléatoires nous permettent de visualiser l'importance des différentes variables explicatives, ci-dessous sur le modèle **foret_ouvre_1**.

```{r, echo=FALSE, include=TRUE}
vip(foret_ouvre_1, num_features=13)
```

On observe que la consommation de la veille et les différentes transformations de la température sont les variables déterminantes.

## 4 Modèles additifs généralisés (GAM)

Les GAM sont des modèles particulièrement adaptés à la prédiction de la consommation d'électricité. Nous utilisons des splines de régression cubique et l'équation suivante, où les degrés de liberté **k** ont été choisis à l'aide de la fonction **gam.check** sur le modèle **gam_ouvre_12**, en supposant que ces paramètres doivent être à peu près les mêmes pour chaque modèle.

```{r, eval=FALSE}
equation <- Load~s(Load.48,k=3, bs="cr")+s(Temp_s95, k=5, bs="cr")+s(Temp_s99, k=5, bs="cr")+s(Temp, k=5, bs="cr")+s(toy, k=35, bs="cr")+te(Load.48,Temp_s99)+WeekDays+DLS+Christmas_break+Summer_break+s(Temp_s99_min, k=5)+s(Temp_s99_max, k=5)+s(Temp_s95_min, k=5)+s(Temp_s95_max, k=5)
```



### Modèles variable par variable, pour optimiser la valeur de k

On vient de voir les forêts aléatoires qui nous ont données des résultats satisfaisant mais on peut espérer avoir de meilleurs résultats avec des modèles GAM bien paramétrés. Pour ce faire, on va dans un premier temps effectuer un GAM variable par variable pour comprendre leur influence sur la consommation et pour déterminer le degré de liberté optimal pour bien décrire les données sans pour autant faire un modèle trop complexe (même si compte-tenu du nombre de données à disposition, le risque d'overfitting est assez réduit). Avec les forêts et l'importance des variables, on a une guideline pour choisir lesquelles traiter en premier. Cette partie étant purement explicative, nous ne nous limitons pas à un modèle par heure pour simplifier l'interpretation qui, de toute manière, ne change pas si on observait les 24 résidus à chaque fois.


```{r, echo=FALSE}
g0 <- gam(Load~s(Load.48, k=3, bs="cr"), data=d_ent_ouvre)
plot(d_ent_ouvre$Load, g0$residuals, main = "Résidus pour g0", xlab = "Consommation (MWh)", ylab = "Résidus" )
fit0 <- getViz(g0, nsim = 50)
plot(sm(fit0, 1), n = 400 ) +labs(title="Lien entre Load.48 et la consommation",x="Load.48 (MWh)",y="Consommation (MWh)")+ l_points() + l_fitLine() + l_ciLine()

```

On a la confirmation que Load.48 est une feature essentielle pour la prévision puisque ce simple modèle (où f est une fonction quasi affine donc on peut prendre k=3) explique déjà 89% de la variance. Pour autant, les résidus ne semblent clairement pas suivre une loi normale centrée ce qui laisse présager d'amélioration.

```{r, echo=FALSE}
g2 <- gam(Load~s(Load.48, k=3, bs="cr")+s(Temp_s95_max, k=5, bs="cr")+s(Temp_s99_max, k=5, bs="cr"), data=d_ent_ouvre)
fit2 <- getViz(g2, nsim = 50)
plot(d_ent_ouvre$Load, g2$residuals, main="Résidus pour g2", xlab="Consommation (MWh)",ylab="Résidus", pch=16)
plot(sm(fit2, 2), n = 400) + l_points() + l_fitLine() + l_ciLine()+labs(title="Lien entre Temp_s95_max et la consommation",x="Temp_s95_max (MWh)",y="Consommation (MWh)")
plot(sm(fit2, 3), n = 400) + l_points() + l_fitLine() + l_ciLine()+labs(title="Lien entre Temp_s99_max et la consommation",x="Temp_s95_max (MWh)",y="Consommation (MWh)")
summary(g2)

```
On obtient un R2 de près de 92% donc l'amélioration est notable, d'autant plus qu'on reste avec des degrés de fonctions assez simple (k=5). Dans le prochain GAM, on ajoute toutes les données discrète (heures (via "time of the day") et jours)

```{r, echo=FALSE}
g3 <- gam(Load~s(Load.48, k=3, bs="cr")+s(Temp_s95_max, k=5, bs="cr")+s(Temp_s99_max, k=5, bs="cr")+WeekDays+s(tod, k=24, bs="cr"), data=d_ent_ouvre)
plot(d_ent_ouvre$Load, g3$residuals, main = "Résidus pour g3", xlab = "Consommation (MWh)", ylab = "Résidus" )
fit3 <- getViz(g3, nsim = 50)
summary(g3)
```
On obtient un R2 de plus de 97% et on remarque que même si on laisse un grand degré de liberté pour la dépendance en toy (k=48) cela n'améliore pas le modèle. Cela justifie le fait de faire un modèle par heure plutôt qu'un par demi-heure. 
On traite à part le cas de toy puisque le degré de liberté est moins facilement paramétrable, on décide donc de trouver k par cross validation :

```{r, echo=FALSE, eval=FALSE}
univ<-function(k, block)
{
  g<- gam(Load~s(toy, k=k, bs="cr"), data=d_ent_ouvre[-block,])
  forecast<-predict(g, newdata=d_ent_ouvre[block,])
  return(d_ent_ouvre[block,]$Load-forecast)
}

Nblock<-10
borne_block<-seq(1, nrow(d_ent_ouvre), length=Nblock+1)%>%floor
block_list<-list()
l<-length(borne_block)
for(i in c(2:(l-1)))
{
  block_list[[i-1]] <- c(borne_block[i-1]:(borne_block[i]-1))
}
block_list[[l-1]]<-c(borne_block[l-1]:(borne_block[l]))

K<-c(3:20)
rmseK<-lapply(K, function(k){lapply(block_list, univ,k=k)%>%unlist%>%rmse} )
plot(K, rmseK, type='b', pch=20)
```
On choisit donc k=14 par technique du coude. On réutilisera une cross-validation pour définir la base de spline que l'on va utiliser au final. Mais avant ça on calcul le gam final avec les degrés de liberté obtenus dans cette partie

### Premier modèle GAM (sans découpage heure par heure)

```{r, echo=FALSE}
equation<-Load~s(Load.48, k=3, bs="cr")+s(Temp_s95_max, k=5, bs="cr")+s(Temp_s99_max, k=5, bs="cr")+s(Temp_s95_min, k=5, bs="cr")+s(Temp_s99_min, k=5, bs="cr")+s(Temp_s95, k=5, bs="cr")+s(Temp_s99, k=5, bs="cr")+WeekDays+s(tod, k=24, bs="cr")+s(toy,k=14)+Christmas_break+Summer_break

gtot <- gam(equation, data=d_ent_ouvre)
plot(d_ent_ouvre$Load, gtot$residuals, main = "Résidus pour g3", xlab = "Consommation (MWh)", ylab = "Résidus" )
fittot <- getViz(gtot, nsim = 50)
summary(gtot)


```
On obtient une variance expliquée de l'ordre de 98% sans pour autant avoir un trop grand nombre de paramètres. De plus, les résidus semblent être bruité et ne plus réellement contenir d'information.

```{r, echo=FALSE}
gam.check(gtot) #Je peux faire en sorte de pas plot tout en faisant comme dans la partie sur les qgams
```
On peut tout de même chercher une amélioration en modifiant la base de spline et en les comparant par cross-validation : 

###analyse plus fine : GAM avec découpage heure par heure

Les GAM sont des modèles particulièrement adaptés à la prédiction de la consommation d'électricité. 

```{r, echo=FALSE, eval=FALSE}
univ<-function(k, block, bs)
{
  equationtot<-Load~s(Load.48, k=3, bs=bs)+s(Temp_s95_max, k=5, bs=bs)+s(Temp_s99_max, k=5, bs=bs)+s(Temp_s95_min, k=5, bs=bs)+s(Temp_s99_min, k=5, bs=bs)+s(Temp_s95, k=5, bs=bs)+s(Temp_s99, k=5, bs=bs)+WeekDays+s(tod, k=24, bs=bs)+s(toy,k=14,bs=bs)+Christmas_break+Summer_break
  
  gtot <- gam(equationtot, data=d_ent_ouvre[-block,])
  forecast<-predict(gtot, newdata=d_ent_ouvre[block,])
  return(2)
  #return(d_ent_ouvre[block,]$Load-forecast)
}

K<-c(4:40)
rmseKcr<-lapply(K, function(k){lapply(block_list, univ, k=k, bs="cr")%>%unlist%>%rmse} )
rmseKtp<-lapply(K, function(k){lapply(block_list, univ, k=k, bs='tp')%>%unlist%>%rmse} )
rmseKps<-lapply(K, function(k){lapply(block_list, univ, k=k, bs='ps')%>%unlist%>%rmse} )
rmseKcs<-lapply(K, function(k){lapply(block_list, univ, k=k, bs='cs')%>%unlist%>%rmse} )

par(mfrow=c(1,1))
col<-piratepal("basel", length.out = 9)
plot(K, rmseKcr, type='b', pch=20, ylim= range(rmseKcr, rmseKps), col=col[1])
lines(K, rmseKtp, type='b', pch=20, col=col[2])
lines(K, rmseKps, type='b', pch=20, col=col[3])
lines(K, rmseKcs, type='b', pch=20, col=col[4])
legend("top", col=col, c("cr", "tp", "ps", "cs"), pch=20, ncol=2, bty='n')
```


```{r, echo=FALSE}
################## Cubic regression

# calcul des prédictions
for(i in c(1:H))
{
  assign(paste("pred_ouvre", i, sep="_"), predict(eval(parse(text=paste("gam_ouvre_cr", i, sep="_"))), newdata = eval(parse(text=paste("d_test_ouvre", i, sep="_")))))
}

# affichage des MAPE
mape_ouvre <- c()
for(i in c(1:H))
{
  mape_ouvre <- c(mape_ouvre, mape(eval(parse(text=paste("d_test_ouvre", i, sep="_")))$Load, eval(parse(text=paste("pred_ouvre", i, sep="_")))))
}

# mape_ouvre  # max = 1.55, min = 1.33

plot(mape_ouvre, main = "MAPE en fonction de l'heure, jours ouvrés (année 2019)", xlab = "Heure", ylab = "MAPE (%)", type="l", ylim= c(0,1.8), lab=c(5,4,0), col="blue")
lines(mape_ouvre_RTE, col="red")
legend(x="bottomright", legend=c("GAM","RTE"), col=c("blue","red"), pch=c(15,15))

```

Nous affichons l'attache aux données et la prédiction pour le modèle **gam_ouvre_12**.

```{r, echo=FALSE, include=TRUE}
# midi

rmse(d_test_ouvre_12$Load-pred_ouvre_12)
mape(d_test_ouvre_12$Load,pred_ouvre_12)

# affichage sur les données d'entraînement
d_plot_ouvre_12 <- filter(d_ent_ouvre_12, Year=="2018")
g_plot_ouvre_12 <- predict(gam_ouvre_cr_12, newdata = d_plot_ouvre_12)
plot(d_plot_ouvre_12$toy, d_plot_ouvre_12$Load, main = "Entraînement jours ouvrés à midi", xlab = "Date (année 2018)", ylab = "Consommation (MWh)", type="l", lab=c(5,4,0))
lines(d_plot_ouvre_12$toy, g_plot_ouvre_12, col='red')
legend(x="bottomleft", legend=c("données","gam_ouvre_12"), col=c("black","red"), pch=c(15,15))

# affichage sur les données test
plot(d_test_ouvre_12$toy, d_test_ouvre_12$Load, main = "Validation jours ouvrés à midi", xlab = "Date (année 2019)", ylab = "Consommation (MWh)", type="l", lab=c(5,4,0))
lines(d_test_ouvre_12$toy, pred_ouvre_12, col='red')
legend(x="bottomleft", legend=c("données","gam_ouvre_12"), col=c("black","red"), pch=c(15,15))

# affichage des différentes splines
fit1 <- getViz(gam_ouvre_cr_12, nsim = 50)
# ordre variables : Load48, Temp95, Temp99, Temp, toy
par(mfrow = c(3,2))

plot(sm(fit1, 1), n = 400) + l_points() + l_fitLine() + l_ciLine()
plot(sm(fit1, 2), n = 400) + l_points() + l_fitLine() + l_ciLine()
plot(sm(fit1, 3), n = 400) + l_points() + l_fitLine() + l_ciLine()
plot(sm(fit1, 4), n = 400) + l_points() + l_fitLine() + l_ciLine()
plot(sm(fit1, 5), n = 400) + l_points() + l_fitLine() + l_ciLine()

```

```{r, echo=FALSE, include=TRUE}
gam.check(gam_ouvre_cr_12)
```

*faire une figure avec attaches aux données et validation pour chaque type de modèle, pour pouvoir comparer*

*mettre le code des figures à part*

*étudier les résidus*

## 5 Modèle mixte : stacking des GAM et des forêts

```{r, echo=FALSE}
for(i in c(1:H))
{
  assign(paste("pred_stack_ouvre", i, sep="_"), predict(eval(parse(text=paste("stack_ouvre", i, sep="_"))), data = eval(parse(text=paste("d_test_ouvre_bis", i, sep="_")))))
}

# affichage des MAPE
mape_ouvre <- c()
for(i in c(1:H))
{
  mape_ouvre <- c(mape_ouvre, mape(eval(parse(text=paste("d_test_ouvre_bis", i, sep="_")))$Load, eval(parse(text=paste("pred_stack_ouvre", i, sep="_")))$predictions))
}

# mape_ouvre

plot(mape_ouvre, main = "MAPE en fonction de l'heure, jours ouvrés (année 2019)", xlab = "Heure", ylab = "MAPE (%)", type="l", ylim= c(0,1.8), lab=c(5,4,0), col="blue")
lines(mape_ouvre_RTE, col="red")
legend(x="bottomright", legend=c("GAM+forets","RTE"), col=c("blue","red"), pch=c(15,15))
```






