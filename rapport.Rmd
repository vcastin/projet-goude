---
title: "Prédire la consommation électrique en France"
subtitle: Projet ML pour la prévision, encadré par Yannig Goude
output: html_document
author: Guillaume Principato et Valérie Castin
date: "15/03/22"
---

<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*Je vais remettre en forme pour que les figures soient plus jolies, pour l'instant c'est un premier jet*

*Introduction à écrire*


## 1 Importation et prétraitement des données

```{r packages, echo=FALSE, include=FALSE}
rm(list=objects())

library(tidyverse)
library(readr)
library(dplyr)
library(lubridate)
library(xts)
library(mgcv)
library(mgcViz)
library(gridExtra)
library(yarrr)
library(qgam)
library(magrittr)
library(rpart)
library(party)
library(tree)
library(rpart.plot)
library(progress)
library(plotmo)
library(caret)
library(randomForest)
library(ranger)
library(opera)
library(corrplot)
library(vip)

set.seed(1)

load("MODELES/forets_ouvre.rda")
load("MODELES/forets_we.rda")
load("MODELES/GAM.rda")
```

Les données que nous avons utilisées sont des données EDF, qui nous ont été fournies directement par Yannig Goude. Nous avons donc pu nous concentrer sur les modèles sans avoir à nettoyer la base de données. Elles concernent la consommation électrique globale française (particuliers, entreprises et bâtiments publics confondus), échantillonnée par demi-heure de janvier 2012 à octobre 2022. Il y a en tout 24 variables, ce qui fait un total de $4.5\times 10^{6}$ observations.

```{r donnees, eval=FALSE, echo=TRUE}
d <- readRDS("Data_RTE_janv2012_oc2022.RDS")
```

### 1.1 Les principales variables du problème

Les variables que nous avons exploitées sont les suivantes.

  - Variables temporelles
    + **tod** : time of day, valeur numérique entre 0 et 1 indiquant le moment de la journée
    + **toy** : time of year, valeur numérique entre 0 et 1 indiquant le moment de l'année
    + **Month** : chaîne de caractères indiquant le mois
    + **WeekDays** : chaîne de caractères indiquant le jour de la semaine
    + **BH** : 1 si l'on est un jour férié, 0 sinon
    + **DLS** : 1 si l'on est en heure d'hiver, 0 sinon
    + **Summer_break** : variable à deux niveaux (0 et 10) pour indiquer les vacances d'été
    + **Christmas_break** : variable à deux niveaux (0 et 20) pour indiquer les vacances de Noël
    
  - Variables de consommation électrique (valeurs numériques)
    + **Load** : consommation dans toute la France échantillonnée au pas demi-heure
    + **Load.48** : consommation 24 heures (soit 48 demi-heures) avant
  - Prévisions RTE (valeurs numériques)
    + **Forecast_RTE_dayahead** : prévision de la consommation réalisée la veille (entre 18h et 20h) par RTE pour le lendemain
    + **Forecast_RTE_intraday** : prévision de la consommation réalisée une heure avant par RTE
  - Variables liées à la température (valeurs numériques)
    + **Temp** : température moyenne mesurée par un ensemble de stations météo en France métropolitaine
    + **Temp_s95** : lissage exponentiel de Temp, avec un facteur de lissage $\alpha = 0.95$
    + **Temp_s99** : lissage exponentiel de Temp, avec un facteur de lissage $\alpha = 0.99$
    + **Temp_s95_min** : minimum des températures mesurées par les différentes stations météo, après lissage avec $\alpha = 0.95$
    + **Temp_s99_min** : minimum des températures mesurées par les différentes stations météo, après lissage avec $\alpha = 0.99$
    + **Temp_s95_max** : maximum des températures mesurées par les différentes stations météo, après lissage avec $\alpha = 0.95$
    + **Temp_s99_max** : maximum des températures mesurées par les différentes stations météo, après lissage avec $\alpha = 0.99$.

### 1.2 Analyse descriptive préliminaire

Commençons par afficher la consommation électrique sur un mois, par exemple avril 2012.

```{r, echo=FALSE, include=TRUE}
n <- 48*(59+32)
m <- 48*(59+32+30)
d_plot <- d[n:m,]
plot(d_plot$Date, d_plot$Load, xlab = "Jour (avril 2012)", ylab = "Consommation (MWh)", type="l")
```


On observe plusieurs périodicités dans la série temporelle :

- des oscillations journalières, de période 24h, avec des pics de consommation à certaines heures
- une périodicité hebdomadaire, avec une nette différence entre les jours ouvrés et les week-ends (ceux-ci coïncidant avec une consommation plus faible).

On s'attend aussi à avoir une périodicité annuelle. Pour la voir, nous représentons la consommation entre 2012 et 2014 pour un jour de la semaine fixé (par exemple le mardi) à une heure donnée (ici 12h), sinon il y a trop de données pour que les courbes soient lisibles.

```{r, echo=FALSE, include=TRUE}
d_plot <- filter(d, Year >= 2013 & Year <= 2016 & WeekDays == "Tuesday" & tod == 24)
plot(d_plot$Date, d_plot$Load, xlab = "Mardi à 12h", ylab = "Consommation (MWh)", type="l")
```

On voit que la consommation est nettement plus importante l'hiver, et on retrouve les vacances d'été et les vacances de Noël en creux.

Ces observations nous incitent à traiter différemment chaque heure de la journée, et à distinguer les jours ouvrés des jours fériés, ce que nous faisons dans la sous-partie suivante. Quelles sont ensuite les variables explicatives les plus pertinentes pour prédire la consommation ? Nous ferons une étude plus approfondie dans la partie sur les forêts aléatoires, en nous fondant sur l'importance des variables, mais nous pouvons dans un premier temps afficher la corrélation entre les variables.

```{r, echo = FALSE, include = TRUE}
d_plot <- select(d, Load, Load.48, Temp, Temp_s95, tod, toy, Year)
d_plot <- filter(d_plot, Year <= 2019)
d_plot <- select(d_plot, Load, Load.48, Temp, Temp_s95, tod, toy)
colnames(d_plot) <- c("Load", "Load.48", "Temp", "Temp_s95", "tod", "toy")
corrplot(cor(d_plot), 
        type = "upper",
        method = "circle",
        order = "hclust",
        hclust.method = "ward.D",
        title = "Corrélation des variables (période 2012 - 2019)",
        mar = c(2, 1, 3, 1))

```

La température (telle quelle ou lissée) apparaît comme étant très anticorrélée à la consommation, ce qui est naturel : lorsqu'il fait froid, les bâtiments sont chauffés, ce qui consomme beaucoup. L'effet de la climatisation lorsqu'il fait chaud compense un peu cette tendance, mais implique une augmentation moindre de la consommation. La consommation de la veille, **Load.48**, est au contraire très corrélée à **Load**. Quant à **tod** et **toy**, elles sont assez faiblement corrélées à **Load** car la tendance s'inverse au fil de leur augmentation : par exemple pour **toy**, la corrélation est d'abord négative, car plus on s'éloigne de janvier et plus les températures remontent, induisant une baisse de la consommation, mais dès que l'automne puis l'hiver reviennent, la corrélation devient positive, et les deux effets se compensent.

### 1.3 Découpage du jeu de données

En vue d'appliquer des modèles d'apprentissage, il nous faut séparer les données qui ont été obtenues dans des conditions trop différentes, pour que l'hypothèse de données identiquement distribuées soit raisonnablement satisfaite. Tout d'abord, les données de la période covid (notamment celles de l'année 2020) ne peuvent vraisemblablement pas être traitées comme celles des années précédentes. Nous choisissons donc comme ensemble d'entraînement la période de 2012 à 2018 inclus, et l'année 2019 sert d'ensemble de validation. Nous enlevons ensuite les jours fériés, qui correspondent à un changement ponctuel de la consommation, et nous séparons les jours ouvrés des week-ends, en vertu des observations réalisées dans la sous-partie précédente.

```{r, echo=TRUE, eval=TRUE}
d_ent <- filter(d, Year<=2018) # on entraîne entre 2012 et 2018
d_test <- filter(d, Year==2019) # on teste sur 2019

# on enlève les jours fériés
d_ent <- filter(d_ent, BH == 0)
d_test <- filter(d_test, BH == 0)

# on distingue les jours ouvrés des week-ends
d_ent_ouvre <- filter(d_ent, WeekDays != "Saturday" & WeekDays != "Sunday")
d_test_ouvre <- filter(d_test, WeekDays != "Saturday" & WeekDays != "Sunday")

d_ent_we <- filter(d_ent, WeekDays =="Saturday" | WeekDays == "Sunday")
d_test_we <- filter(d_test, WeekDays =="Saturday" | WeekDays == "Sunday")
```

Pour avoir des modèles aussi précis que possible, mais aussi alléger le coût d'entraînement, puisque notre jeu de données est assez volumineux, nous avons entraîné un modèle différent par demi-heure. Nous avons sélectionné 24 demi-heures sur 48 (les premières demi-heures de chaque heure), pour faciliter l'affichage des résultats : cela ne change rien aux méthodes étudiées. Nous obtenons ainsi les jeux de données :

- **d_ent_ouvre_i** pour $1\le i\le 24$, où l'on n'a gardé que les jours ouvrés dans **d_ent**, à l'heure $i$,
- **d_ent_we_i** pour $1\le i\le 24$, où l'on n'a gardé que les week-ends dans **d_ent**, à l'heure $i$,
- **d_test_ouvre_i** pour $1\le i\le 24$, où l'on n'a gardé que les jours ouvrés dans **d_test**, à l'heure $i$,
- **d_test_we_i** pour $1\le i\le 24$, où l'on n'a gardé que les week-ends dans **d_test**, à l'heure $i$.

```{r, eval=TRUE, echo=FALSE}
# construction d'un data frame par heure
H <- 24

for(i in c(1:H))
{
  assign(paste("d_ent_ouvre", i, sep="_"),filter(d_ent_ouvre, tod==i)) # d_ent_ouvre_i
}

for(i in c(1:H))
{
  assign(paste("d_ent_we", i, sep="_"),filter(d_ent_we, tod==i)) # d_ent_we_i
}

for(i in c(1:H))
{
  assign(paste("d_test_ouvre", i, sep="_"),filter(d_test_ouvre, tod==i)) # d_test_ouvre_i
}

for(i in c(1:H))
{
  assign(paste("d_test_we", i, sep="_"),filter(d_test_we, tod==i)) # d_test_we_i
}
```


## 2 Évaluation des modèles : quelques repères

Pour évaluer la performance de nos modèles, nous introduisons la classique perte quadratique (RMSE), et également l'erreur absolue moyenne en pourcentage (MAPE), que nous allons majoritairement exploiter en tant que grandeur "absolue" sans dimension :

$$\text{RMSE}(\varepsilon) = \sqrt{\frac{1}{T}\sum_{i=1}^T \varepsilon_i^2},$$
et
$$\text{MAPE}(Y,\hat{Y}) = 100 \times \frac{1}{T}\sum_{i=1}^T\left \lvert \frac{Y_i-\hat{Y}_i}{Y_i}\right \rvert.$$

```{r, eval=FALSE, echo=FALSE}
rmse <- function(eps)
{
  return(round(sqrt(mean(eps^2,na.rm=TRUE)), digits=0))
}

mape <- function(y,ychap)
{
  return(round(100*mean(abs(y-ychap)/abs(y)), digits=2))
}
```

Pour avoir une idée du positionnement de nos modèles en termes de performance, et de l'utilité de recourir au machine learning pour répondre à notre problème, nous pouvons nous comparer :

- au modèle naïf *à faire : je pensais à Load.48, est-ce que tu aurais d'autres idées ?*
- aux prévisions RTE : sur le jeu de données test (année 2019), on calcule les MAPE suivants pour **Forecast_RTE_intraday** pour les jours ouvrés (en pourcentage, dans l'ordre croissant par heure)

```{r, echo=FALSE, include=TRUE}
mape_ouvre_RTE <- c()
for(i in c(1:H))
{
  mape_ouvre_RTE <- c(mape_ouvre_RTE, mape(eval(parse(text=paste("d_test_ouvre", i, sep="_")))$Load, eval(parse(text=paste("d_test_ouvre", i, sep="_")))$Forecast_RTE_intraday))
}
mape_ouvre_RTE
```

et les MAPE suivants pour le week-end :

```{r, echo=FALSE, include=TRUE}
mape_we_RTE <- c()
for(i in c(1:H))
{
  mape_we_RTE <- c(mape_we_RTE, mape(eval(parse(text=paste("d_test_we", i, sep="_")))$Load, eval(parse(text=paste("d_test_we", i, sep="_")))$Forecast_RTE_intraday))
}
mape_we_RTE
```

Soulignons que dans ses prévisions une heure à l'avance, RTE ne dispose que de prévisions météo, alors que nos modèles exploitent des valeurs de température effective, ce qui joue à notre avantage.

## 3 Forêts aléatoires

Un premier modèle assez adapté à notre problématique est celui des forêts aléatoires. Dans un premier temps, nous avons entraîné une forêt sur l'ensemble des données, sans la séparation des heures et des jours ouvrés/week-ends. Nous obtenons un MAPE de 1.8% sur les données test. Nous avons ensuite séparé les données conformément à la partie 1.3, et les résultats sont nettement meilleurs : c'est donc ce choix que nous développons dans cette partie. Nous avons utilisé le package *ranger*, et mis dans chaque modèle toutes les variables explicatives potentiellement pertinentes.

### 3.1 Choix des paramètres

Les paramètres à choisir pour définir nos forêts aléatoires sont les suivants.

- **mtry** : nombre de variables sélectionnées à chaque nouvelle coupure dans les arbres. Nous réalisons une validation croisée sur le modèle **d_ent_ouvre_1**, les autres modèles se comportant de façon similaire, et choisissons **mtry** = 8, car la courbe est à peu près constante à partir de cette valeur.

```{r, echo=FALSE, eval=FALSE}
##### jours ouvrés

formule_1 <- "Load ~ Temp_s99+toy+WeekDays+Temp_s95+Load.48+Christmas_break+Summer_break+DLS+Temp+Temp_s95_min+Temp_s95_max+Temp_s99_min+Temp_s99_max"

# choix de mtry par validation croisée sur le premier modèle

grid_mtry <-  expand.grid(mtry = seq(1,10,by=1), 
                          min.node.size = 5,
                          splitrule = "variance")

fitControl <- trainControl(method="cv", number=16,
                           verboseIter = TRUE)

fit = caret::train(
  x = d_ent_ouvre_1,
  y = d_ent_ouvre_1$Load,
  method = 'ranger',
  num.trees = 100,
  tuneGrid = grid_mtry,
  trControl = fitControl)

#print(fit)

p <- plot(fit, main = "Choix du paramètre mtry par validation croisée \n Jeu de données : d_ent_ouvre_1", xlab = "mtry", ylab="RMSE")
print(p)
```
```{r, out.width='80%', fig.align='center', fig.show='hold', echo = F}
knitr::include_graphics('FIGURES/choix_mtry_forets')
```


- **min.node.size** : les fluctuations de RMSE induites par le changement de ce paramètre sont faibles, d'après la courbe ci-dessous. Nous laissons donc **min.node.size** à sa valeur par défaut (5).

```{r, echo=FALSE, eval=FALSE}
# choix de min.node.size par validation croisée sur le premier modèle

grid_minnode <-  expand.grid(mtry = 8, 
                             min.node.size = seq(1, 10, by = 1),
                             splitrule = "variance")

fitControl <- trainControl(method="cv", number=16,
                           verboseIter = TRUE)

fit = caret::train(
  x = d_ent_ouvre_1,
  y = d_ent_ouvre_1$Load,
  method = 'ranger',
  num.trees = 100,
  tuneGrid = grid_minnode,
  trControl = fitControl)

#print(fit)

p <- plot(fit, main = "Choix du paramètre min.node.size par validation croisée \n Jeu de données : d_ent_ouvre_1", xlab = "min.node.size", ylab="RMSE")
print(p)
```
```{r, out.width='80%', fig.align='center', fig.show='hold', echo = F}
knitr::include_graphics('FIGURES/choix_minnode_forets')
```


- **num.trees** : au vu de la courbe ci-dessous, nous choisissons de prendre 150 arbres, ce qui est un peu au-delà de la valeur où la courbe forme un coude, mais nous pouvons nous le permettre car nos jeux de données par heure ne sont pas très volumineux.

```{r, echo=FALSE, eval=FALSE}
error_list <- c()
ntree_list <- seq(25,400,25)

# For each number of trees...
for(n in ntree_list){
  #print(n) # to check the loop
  
  #ptm <- proc.time() # evaluate execution time
  
  # Grow a forest with n trees
  res <- ranger(formule_1, 
                data=d_ent_ouvre_1, 
                num.trees = n,
                mtry=8,
                importance='permutation')
  
  #temp <- proc.time() - ptm
  
  #time_list <- c(time_list, temp[3])
  
  error_list <- c(error_list, res$prediction.error)
}

# plotting results


p <- plot(ntree_list, error_list, 
           main = "RMSE en fonction du nombre d'arbres \n Jeu de données : d_ent_ouvre_1", 
           xlab = "ntree", 
           ylab="RMSE",
           type = "o",
           pch=18,
           col="blue")


print(p)

```

```{r, out.width='80%', fig.align='center', fig.show='hold', echo = F}
knitr::include_graphics('FIGURES/choix_ntree_forets')
```


### 3.2 Entraînement et évaluation des modèles

Une fois les paramètres choisis, nous pouvons entraîner nos modèles.

```{r, eval=FALSE, echo=TRUE}
##### jours ouvrés

formule_1 <- "Load ~ Temp_s99+toy+WeekDays+Temp_s95+Load.48+Christmas_break+Summer_break+DLS+Temp+Temp_s95_min+Temp_s95_max+Temp_s99_min+Temp_s99_max"

# calcul des modèles
for(i in c(1:H))
{
  assign(paste("foret_ouvre", i, sep="_"), ranger(formule_1, data=eval(parse(text=paste("d_ent_ouvre", i, sep="_"))), importance = "permutation", num.trees = 150, mtry=8))
}
```

```{r, echo=FALSE}
# calcul des prédictions
for(i in c(1:H))
{
  assign(paste("pred_foret_ouvre", i, sep="_"), predict(eval(parse(text=paste("foret_ouvre", i, sep="_"))), data = eval(parse(text=paste("d_test_ouvre", i, sep="_")))))
}
```

```{r, echo=FALSE, include=TRUE}
# affichage des MAPE
mape_ouvre <- c()
for(i in c(1:H))
{
  mape_ouvre <- c(mape_ouvre, mape(eval(parse(text=paste("d_test_ouvre", i, sep="_")))$Load, eval(parse(text=paste("pred_foret_ouvre", i, sep="_")))$predictions))
}

plot(mape_ouvre, main = "MAPE en fonction de l'heure, jours ouvrés (année 2019)", xlab = "Heure", ylab = "MAPE (%)", type="l", ylim= c(0,1.7), lab=c(5,4,0))
lines(mape_ouvre_RTE, col="red")
legend(x="bottomright", legend=c("foret","RTE"), col=c("black","red"), pch=c(0,15))
```

Nous affichons l'attache aux données et la prédiction pour le modèle **d_ent_ouvre_1**. *Est-ce qu'on n'overfitte pas un peu ?*

```{r, echo=FALSE, include=TRUE}
# midi
#imp_12 <- importance(foret_ouvre_12)
#imp_12[order(imp_12, decreasing=TRUE)]

#rmse(d_test_ouvre_12$Load-pred_foret_ouvre_12$predictions)
#mape(d_test_ouvre_12$Load,pred_foret_ouvre_12$predictions)

# affichage sur les données d'entraînement
# d_plot_ouvre_12 <- filter(d_ent_ouvre_12, Year=="2018")
# f_plot_ouvre_12 <- predict(foret_ouvre_12, data = d_plot_ouvre_12)
# plot(d_plot_ouvre_12$toy, d_plot_ouvre_12$Load, main = "Entraînement jours ouvrés à midi", xlab = "Date (année 2018)", ylab = "Consommation (MWh)", type="l", lab=c(5,4,0))
# lines(d_plot_ouvre_12$toy, f_plot_ouvre_12$predictions, col='red')
# 
# # affichage sur les données test
# plot(d_test_ouvre_12$toy, d_test_ouvre_12$Load, main = "Validation jours ouvrés à midi", xlab = "Date (année 2019)", ylab = "Consommation (MWh)", type="l", lab=c(5,4,0))
# lines(d_test_ouvre_12$toy, pred_foret_ouvre_12$predictions, col='red')


# de minuit à une heure
#imp_1 <- importance(foret_ouvre_1)
#imp_1[order(imp_1, decreasing=TRUE)]

#rmse(d_test_ouvre_1$Load-pred_foret_ouvre_1$predictions)
#mape(d_test_ouvre_1$Load,pred_foret_ouvre_1$predictions)

# affichage sur les données d'entraînement
d_plot_ouvre_1 <- filter(d_ent_ouvre_1, Year=="2018")
f_plot_ouvre_1 <- predict(foret_ouvre_1, data = d_plot_ouvre_1)
plot(d_plot_ouvre_1$toy, d_plot_ouvre_1$Load, main = "Entraînement jours ouvrés à midi", xlab = "Date (année 2018)", ylab = "Consommation (MWh)", type="l", lab=c(5,4,0))
lines(d_plot_ouvre_1$toy, f_plot_ouvre_1$predictions, col='red')

# affichage sur les données test
plot(d_test_ouvre_1$toy, d_test_ouvre_1$Load, main = "Validation jours ouvrés à midi", xlab = "Date (année 2019)", ylab = "Consommation (MWh)", type="l", lab=c(5,4,0))
lines(d_test_ouvre_1$toy, pred_foret_ouvre_1$predictions, col='red')
```

Un code similaire pour le week-end donne comme MAPE :

```{r, echo=FALSE}
##### week-end

# calcul des prédictions
for(i in c(1:H))
{
  assign(paste("pred_foret_we", i, sep="_"), predict(eval(parse(text=paste("foret_we", i, sep="_"))), data = eval(parse(text=paste("d_test_we", i, sep="_")))))
}

```

```{r, echo=FALSE, include=TRUE}
# affichage des MAPE
mape_we <- c()
for(i in c(1:H))
{
  mape_we <- c(mape_we, mape(eval(parse(text=paste("d_test_we", i, sep="_")))$Load, eval(parse(text=paste("pred_foret_we", i, sep="_")))$predictions))
}

plot(mape_we, main = "MAPE en fonction de l'heure, le week-end (année 2019)", xlab = "Heure", ylab = "MAPE (%)", type="l", ylim= c(0,1.8), lab=c(5,4,0))
lines(mape_ouvre_RTE, col="red")
legend(x="bottomright", legend=c("foret","RTE"), col=c("black","red"), pch=c(0,15))

```

### 3.3 Importance des variables

Enfin, les forêts aléatoires nous permettent de visualiser l'importance des différentes variables explicatives, ci-dessous sur le modèle **foret_ouvre_1**.

```{r, echo=FALSE, include=TRUE}
vip(foret_ouvre_1, num_features=13)
```

On observe que la consommation de la veille et les différentes transformations de la température sont les variables déterminantes.

## 4 Modèles additifs généralisés (GAM)

Les GAM sont des modèles particulièrement adaptés à la prédiction de la consommation d'électricité. 

```{r}
################## Cubic regression

# calcul des prédictions
for(i in c(1:H))
{
  assign(paste("pred_ouvre", i, sep="_"), predict(eval(parse(text=paste("gam_ouvre_cr", i, sep="_"))), newdata = eval(parse(text=paste("d_test_ouvre", i, sep="_")))))
}

# affichage des MAPE
mape_ouvre <- c()
for(i in c(1:H))
{
  mape_ouvre <- c(mape_ouvre, mape(eval(parse(text=paste("d_test_ouvre", i, sep="_")))$Load, eval(parse(text=paste("pred_ouvre", i, sep="_")))))
}

mape_ouvre  # max = 1.55, min = 1.33

```

